---
name: ai-vuln-discovery
description: Use when analyzing AI-discovered vulnerabilities, researching AI security audit methodologies, or auditing frameworks for security issues. Use for framework-specific security audits (Laravel, FastAPI, Express, ThinkPHP, Solidity), vulnerability verification with PoC, and business logic flaw detection.
---

# AI驱动漏洞发现分析 (AI Vulnerability Discovery Analysis)

分析AI系统发现的漏洞,提取技术方法、架构模式和最佳实践。

## 何时使用

- 分析AI自主发现的0-day漏洞案例
- 研究AI安全审计系统的工作原理
- 提取AI漏洞发现的技术架构
- 对比不同AI安全平台的方法论

## 分析框架

### 1. 公司/平台背景分析

提取以下信息:
- 公司定位 (AI-native security / Autonomous ethical hacking)
- 背书/投资 (如 Y Combinator)
- 团队背景和技术积累
- 目标市场和客户群体

### 2. 技术架构五阶段模型

基于Winfunc方法论,AI漏洞发现系统通常包含以下阶段:

| 阶段 | 功能 | 关键技术 |
|------|------|----------|
| **Indexing** | 构建代码语义图谱 | Tree-sitter, LSP, 调用图/数据流/控制流分析 |
| **Threat Modeling** | 生成攻击假设 | LLM生成创意攻击场景,超越已知模式 |
| **Analysis & Exploitation** | 代码路径追踪与Payload生成 | Monte Carlo Tree Self-Refine |
| **Verification** | 实际验证漏洞可利用性 | 沙箱环境执行,CPU/内存/崩溃检测 |
| **Disclosure** | 报告与修复建议 | 自动生成PoC和修复PR |

### 3. 核心技术要素

#### 3.1 代码理解层
- **语言支持**: 主流语言 + 小众语言 (Haskell, Elixir, Clojure, Arc等)
- **语义分析**: 调用图、数据流、类型信息、控制流
- **Context理解**: Sink-to-source分析,金融逻辑验证,授权绕过检测

#### 3.2 AI/LLM应用层
- **攻击假设生成**: 利用LLM的"幻觉"能力产生fuzzing无法生成的创意场景
- **迭代优化**: Tryhard agent链式漏洞组合,将假设变为现实
- **语义理解**: 理解代码意图而非仅模式匹配

#### 3.3 验证与PoC层
- **零误报承诺**: "PoC || GTFO" - 无法利用则不报告
- **形式化验证**: 确定性可复现的漏洞利用
- **沙箱执行**: 测量CPU、内存、崩溃状态

### 4. 漏洞类型覆盖

AI系统特别擅长发现:

| 漏洞类型 | 检测方法 |
|----------|----------|
| **权限绕过** | 理解权限模型意图与实现差距 |
| **竞争条件/TOCTOU** | 复杂执行路径分析 |
| **内存安全** | 深层代码路径追踪 |
| **业务逻辑漏洞** | 语义理解与金融逻辑验证 |
| **架构漂移** | 历史模式分析与变更检测 |

### 5. 与传统方法的对比

| 维度 | 传统SAST/人工审计 | AI自主发现 |
|------|-------------------|------------|
| **方法** | 已知漏洞模式匹配 | 语义理解 + 创意生成 |
| **覆盖** | 已知CVE类型 | 新型0-day无文档模式 |
| **误报** | 较高,需人工筛选 | 零误报(强制验证) |
| **规模** | 受人工时间限制 | 自动化持续运行 |
| **语言** | 主流语言支持 | 全语言支持(含小众) |

### 6. 实践案例分析模板

分析具体漏洞发现案例时,按以下结构记录:

```markdown
## 案例: [CVE编号] - [漏洞名称]

### 基本信息
- **发现平台**: Winfunc/Ethiack/其他
- **发现时间**:
- **影响组件**:
- **漏洞类型**:

### 技术细节
- **根本原因**:
- **攻击向量**:
- **利用条件**:

### AI发现方法
- **威胁建模**: AI如何生成攻击假设
- **代码分析**: 哪些代码路径被追踪
- **验证过程**: 如何确认漏洞可利用

### 与传统方法的差异
- 为什么传统SAST/人工审计没发现
- AI的哪些能力促成了发现

### 修复建议
- 官方修复方案
- 预防此类漏洞的最佳实践
```

## 输出规范

分析完成后,输出应包含:
1. **技术架构图**: 五阶段流程图
2. **核心能力矩阵**: AI vs 传统方法对比
3. **案例库**: 具体漏洞发现案例分析
4. **方法论总结**: 可复用的漏洞发现模式

## 7. 框架特定审计方法论

### 7.1 审计准备阶段

**核心原则**: 不了解框架就无法发现框架层面的漏洞

| 准备项 | 目的 | 关键问题 |
|--------|------|----------|
| **框架文档学习** | 理解标准用法和最佳实践 | 框架推荐的安全写法是什么? |
| **验证环境搭建** | 确保测试环境可复现 | 该技术栈用什么工具验证最合适? |
| **历史漏洞研究** | 了解该版本的已知安全问题 | 该版本有哪些CVE?修复了吗? |
| **升级日志分析** | 发现安全修复模式 | 官方修复了哪些安全问题? |

### 7.2 框架审计核心思路

#### 第一层: 框架知识储备

审计任何框架前,必须理解:
- **请求生命周期**: 请求如何进入、如何处理、如何响应
- **核心组件**: 路由、控制器、模型、中间件的工作机制
- **安全机制**: 框架提供的认证、授权、输入验证机制
- **标准写法**: 官方推荐的安全编码规范

#### 第二层: 框架特定风险点

不同框架有不同的"危险区域":

| 框架类型 | 典型风险点 | 审计关注点 |
|----------|------------|------------|
| **MVC框架(Laravel/ThinkPHP)** | 模型层数据操作、模板渲染、路由配置 | ORM使用方式、模板语法、中间件缺失 |
| **异步框架(FastAPI/Express)** | 依赖注入、异步执行流、文件操作 | Depends验证、并发处理、路径拼接 |
| **全栈框架(Next.js/Nuxt)** | 服务端渲染、API路由、客户端 hydration | SSR数据注入、API鉴权、hydration攻击 |

#### 第三层: 历史漏洞模式

**必须检查的内容**:
- 当前使用的框架版本是否存在已知CVE
- 项目是否应用了官方安全补丁
- 危险函数/方法的使用方式(如eval、unserialize、system等)
- 框架特定的漏洞模式(如ThinkPHP的模板注入、Laravel的反序列化链)

### 7.3 业务逻辑漏洞审计思路

**核心方法: 对比标准写法与实际写法**

1. **识别业务场景**: 定位涉及资金、权限、数据变更的关键业务
2. **查找标准实现**: 框架官方文档推荐的安全实现方式
3. **对比实际代码**: 项目中的实现与标准实现的差异点
4. **分析差异风险**: 差异是否引入了安全漏洞

**典型业务风险点**:
| 业务场景 | 审计思路 | 常见漏洞 |
|----------|----------|----------|
| **资金操作** | 检查金额验证逻辑 | 负数金额、精度丢失、并发竞争 |
| **权限控制** | 检查鉴权粒度 | 水平越权、垂直越权、未授权访问 |
| **数据操作** | 检查输入验证 | 类型混淆、格式绕过、注入攻击 |
| **批量操作** | 检查限制机制 | 批量越权、资源耗尽、条件竞争 |

**数据库结构审计**:
- 字段类型是否与业务逻辑匹配(如金额字段类型)
- 约束条件是否完整(外键、唯一性、非空)
- 索引是否合理(影响查询性能和拖库风险)

### 7.4 框架版本与漏洞关系

**关键原则**: 框架版本决定漏洞是否存在

审计时必须:
1. **确认精确版本**: 不能只知道是大版本(如ThinkPHP 5),必须知道小版本(如5.0.22)
2. **查询版本CVE**: 该版本存在的已知漏洞
3. **验证漏洞修复**: 项目是否应用了补丁或规避了漏洞
4. **检查依赖传递**: 框架依赖的组件版本是否安全

## 8. 漏洞验证方法论

### 8.1 验证的核心原则

**"断言漏洞存在的唯一方式是成功利用"**

代码分析只能发现"可能的漏洞",必须通过实际验证确认:
- **搭建验证环境**: 根据技术栈选择合适的环境和工具
- **编写测试用例**: 单元测试或模糊测试验证漏洞可利用性
- **执行PoC**: 可重复执行的漏洞利用代码

### 8.2 验证环境选择

根据技术栈选择最适合的验证环境:

| 技术栈 | 推荐环境/工具 | 测试能力 |
|--------|---------------|----------|
| **Web应用(PHP/Python/Node等)** | Docker容器 | 隔离运行环境,模拟生产配置 |
| **Solidity智能合约** | Foundry/Forge | 单元测试、模糊测试、状态模拟 |
| **Java应用** | Maven/Gradle + TestContainers | 依赖管理、集成测试 |
| **Rust程序** | Cargo + 自定义测试框架 | 内存安全测试、并发测试 |
| **移动应用** | 模拟器/真机 + Frida | 运行时分析、动态调试 |

**环境选择原则**:
- 选择能最准确模拟目标运行环境的工具
- 优先使用目标生态的标准测试框架
- 确保环境可复现、可版本控制

### 8.3 验证流程

| 步骤 | 目标 | 关键活动 |
|------|------|----------|
| **环境搭建** | 创建可复现的测试环境 | 根据技术栈选择工具,配置依赖 |
| **漏洞触发** | 构造触发漏洞的输入 | 编写测试用例、准备Payload |
| **结果验证** | 确认漏洞被成功利用 | 断言验证、状态检查、日志分析 |
| **修复验证** | 确认修复后漏洞不可用 | 回归测试、边界条件测试 |

### 8.4 PoC编写规范

**PoC应包含的核心要素**:
1. **漏洞描述**: 什么漏洞、如何触发、影响范围
2. **环境要求**: 运行PoC所需的环境和工具
3. **检测方法**: 如何判断目标是否存在漏洞
4. **利用逻辑**: 如何构造请求/数据触发漏洞
5. **结果验证**: 如何确认漏洞被成功利用
6. **修复验证**: 如何验证漏洞已修复

**PoC设计原则**:
- **确定性**: 同一环境下多次执行结果一致
- **可复现**: 任何人在相同环境下都能复现
- **安全性**: 不对非目标系统造成影响
- **最小化**: 仅包含触发漏洞的最小必要代码

## 9. 漏洞分析流程总结

```
开始审计
    │
    ▼
┌─────────────────────────────────┐
│ 1. 框架学习与环境准备            │
│    - 阅读官方文档理解标准用法    │
│    - 搭建适合技术栈的验证环境    │
└─────────────────┬───────────────┘
                  │
                  ▼
┌─────────────────────────────────┐
│ 2. 版本与历史漏洞分析            │
│    - 确认框架精确版本            │
│    - 查询该版本的CVE和修复       │
└─────────────────┬───────────────┘
                  │
                  ▼
┌─────────────────────────────────┐
│ 3. 代码差异分析                  │
│    - 对比标准写法与实际写法      │
│    - 识别业务逻辑漏洞点          │
└─────────────────┬───────────────┘
                  │
                  ▼
┌─────────────────────────────────┐
│ 4. 漏洞验证                      │
│    - 选择合适环境/工具           │
│    - 编写PoC脚本/测试用例        │
│    - 执行验证并记录结果          │
└─────────────────┬───────────────┘
                  │
                  ▼
┌─────────────────────────────────┐
│ 5. 报告与修复验证                │
│    - 输出漏洞详情和修复建议      │
│    - 验证修复有效性              │
└─────────────────────────────────┘
```

## 10. 关键审计原则

1. **框架知识优先**: 不了解框架就无法审计框架层面的漏洞
2. **版本是关键**: 同样的代码在不同版本可能有完全不同的安全风险
3. **对比找差异**: 通过对比标准写法与实际写法发现安全问题
4. **验证为王**: 只有通过PoC验证的漏洞才能确认存在
5. **业务逻辑不可忽视**: 框架安全不代表业务逻辑安全

## 注意事项

- AI发现漏洞强调"理解意图"而非"匹配模式"
- 零误报是通过强制PoC验证实现的,非静态分析
- LLM的"幻觉"在创意攻击生成中是优势而非缺陷
- 小众语言支持是AI系统的差异化能力
